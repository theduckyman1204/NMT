{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'nltk' from 'sklearn' (C:\\Users\\asus vivobook\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nltk\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'nltk' from 'sklearn' (C:\\Users\\asus vivobook\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_path = \"D:\\\\NLP\\\\train.en\"\n",
    "vn_path = \"D:\\\\NLP\\\\train.vi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "en_data = load_data(en_path)\n",
    "vn_data = load_data(vn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rachel Pike : The science behind a climate hea...</td>\n",
       "      <td>Khoa học đằng sau một tiêu đề về khí hậu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In 4 minutes , atmospheric chemist Rachel Pike...</td>\n",
       "      <td>Trong 4 phút , chuyên gia hoá học khí quyển Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I &amp;apos;d like to talk to you today about the ...</td>\n",
       "      <td>Tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Headlines that look like this when they have t...</td>\n",
       "      <td>Có những dòng trông như thế này khi bàn về biế...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They are both two branches of the same field o...</td>\n",
       "      <td>Cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0  Rachel Pike : The science behind a climate hea...   \n",
       "1  In 4 minutes , atmospheric chemist Rachel Pike...   \n",
       "2  I &apos;d like to talk to you today about the ...   \n",
       "3  Headlines that look like this when they have t...   \n",
       "4  They are both two branches of the same field o...   \n",
       "\n",
       "                                          Vietnamese  \n",
       "0           Khoa học đằng sau một tiêu đề về khí hậu  \n",
       "1  Trong 4 phút , chuyên gia hoá học khí quyển Ra...  \n",
       "2  Tôi muốn cho các bạn biết về sự to lớn của nhữ...  \n",
       "3  Có những dòng trông như thế này khi bàn về biế...  \n",
       "4  Cả hai đều là một nhánh của cùng một lĩnh vực ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'English': en_data,\n",
    "    'Vietnamese': vn_data\n",
    "})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí tiếng anh: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí tiếng Việt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "def clean_text_vietnamese(text):\n",
    "    text = re.sub(r\"[^\\w\\s.,!?-]\", \"\", text) \n",
    "    text = text.lower() \n",
    "    return text\n",
    "\n",
    "def tokenize_vietnamese(text):\n",
    "    return ViTokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vietnamese_stopwords = [\n",
    "    \"là\", \"và\", \"của\", \"có\", \"với\", \"cho\", \"vì\", \"này\", \"đã\", \"đang\", \n",
    "    \"tôi\", \"bạn\", \"anh\", \"chị\", \"nó\", \"thì\", \"một\", \"cái\", \"những\", \n",
    "    \"các\", \"ở\", \"trên\", \"dưới\", \"khi\", \"nếu\", \"lại\", \"thế\", \"này\", \n",
    "    \"kia\", \"rằng\", \"rất\", \"để\", \"đến\", \"nơi\", \"từ\", \"hơn\", \"nữa\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopwords):\n",
    "    return \" \".join([word for word in text.split() if word not in stopwords])\n",
    "def add_special_tokens(sentence):\n",
    "    return \"<sos> \" + sentence + \" <eos>\"\n",
    "from collections import Counter\n",
    "\n",
    "def build_vocabulary(tokenized_sentences, min_freq=1):\n",
    "    vocab = Counter(word for sentence in tokenized_sentences for word in sentence.split())\n",
    "    vocab = {word: idx for idx, (word, freq) in enumerate(vocab.items(), start=4) if freq >= min_freq}\n",
    "    vocab['<pad>'] = 0\n",
    "    vocab['<sos>'] = 1\n",
    "    vocab['<eos>'] = 2\n",
    "    vocab['<unk>'] = 3\n",
    "    return vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
